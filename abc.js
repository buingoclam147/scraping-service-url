// xoÃ¡ cÃ¡c container, image, volume vÃ  network khÃ´ng sá»­ dá»¥ng
// docker-compose down --volumes --remove-orphans
// docker system prune -af --volumes
// docker builder prune --all --force

// docker-compose build --no-cache
// docker-compose up
import chromium from "@sparticuz/chromium";
import express from "express";
import PQueue from 'p-queue';
import puppeteer from 'puppeteer-extra';
import StealthPlugin from 'puppeteer-extra-plugin-stealth';
puppeteer.use(StealthPlugin());
const app = express();
app.use(express.json());
const PORT = process.env.PORT || 3000;
const scrapeQueue = new PQueue({ concurrency: 3 }); // Chá»‰ cho phÃ©p 3 job cháº¡y song song

app.post("/scrape", async (req, res) => {
  await scrapeQueue.add(() => handleScrapeWithRetry(req, res));
});

async function handleScrapeWithRetry(req, res) {
  let attempt = 0;
  const maxRetries = 2;

  while (attempt <= maxRetries) {
    try {
      console.log(`ðŸ” Attempt ${attempt + 1}`);
      await handleScrape(req, res);
      return;
    } catch (error) {
      attempt++;
      console.error(`âŒ Lá»—i á»Ÿ attempt ${attempt}:`, error.message);
      if (attempt > maxRetries) {
        console.error(`ðŸš« Táº¥t cáº£ ${maxRetries + 1} attempt Ä‘á»u tháº¥t báº¡i.`);
        return res.status(500).json({ error: 'Scraping failed after retries' });
      }
    }
  }
}

async function handleScrape(req, res) {
  const { url, mode = 'html', actions = [], proxy } = req.body;
  if (!url) return res.status(400).json({ error: "URL is required" });

  const launchArgs = [
    '--no-sandbox',
    '--disable-setuid-sandbox',
    '--disable-dev-shm-usage',
    '--disable-accelerated-2d-canvas',
    '--disable-gpu',
    '--no-zygote',
    '--single-process',
    '--disable-web-security',
    '--disable-blink-features=AutomationControlled'
  ];

  if (proxy) {
    // Sá»­ dá»¥ng SOCKS5 proxy
    launchArgs.push(`--proxy-server=socks5://${proxy}`);
    console.log(`ðŸ”Œ Sá»­ dá»¥ng SOCKS5 proxy: ${proxy}`);
  }

  const browser = await puppeteer.launch({
    args: [...chromium.args, ...launchArgs],
    defaultViewport: chromium.defaultViewport,
    headless: 'new',
  });

  let page;
  try {
    page = await browser.newPage();
    await page.setUserAgent('Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3');
    await page.setDefaultNavigationTimeout(300000);
    await page.goto(url, { waitUntil: 'networkidle2' });

    let result = null;

    if (mode === 'js' && actions.length > 0) {
      for (const action of actions) {
        switch (action.type) {
          case 'click': await page.click(action.selector); break;
          case 'scroll': await page.evaluate((y) => window.scrollBy(0, y), action.y || 500); break;
          case 'waitForSelector': await page.waitForSelector(action.selector, { timeout: 10000 }); break;
          case 'type': await page.type(action.selector, action.value || ''); break;
          case 'html': result = await page.content(); break;
          case 'evaluate': result = await page.evaluate(eval(action.script)); break;
          case 'delay': await new Promise(resolve => setTimeout(resolve, action.ms || 1000)); break;
          default: console.warn(`âš ï¸ KhÃ´ng há»— trá»£: ${action.type}`);
        }
      }
    } else {
      result = await page.content();
    }

    return res.json({ success: true, data: result });

  } catch (error) {
    console.error('âŒ Lá»—i scraping:', error.message);
    return res.status(500).json({ error: error.message });

  } finally {
    if (page) await page.close();
    await browser.close(); // âš ï¸ ÄÃ³ng browser sau má»—i request
  }
}


// Health check endpoint
app.get('/health', (req, res) => {
  res.status(200).json({ status: 'OK' });
});

// Khá»Ÿi Ä‘á»™ng server
async function startServer() {
  app.listen(PORT, '0.0.0.0', () => {
    console.log(`Server Ä‘ang cháº¡y táº¡i http://localhost:${PORT}`);
    console.log(`API scraping cÃ³ sáºµn táº¡i http://localhost:${PORT}/scrape`);
  });
}

startServer();
